# Unifor DataOps Pipeline

Este projeto implementa um pipeline de dados completo utilizando **Apache Airflow**, **MongoDB**, **PostgreSQL** e **Streamlit**, com o objetivo de realizar a ingestÃ£o, transformaÃ§Ã£o, armazenamento e visualizaÃ§Ã£o de dados da API pÃºblica do [TabNews](https://www.tabnews.com.br).

![image](https://github.com/user-attachments/assets/91e7bad0-55ed-4de5-8106-48714d0c2f5d)

---

## ğŸ› ï¸ Tecnologias Utilizadas

- [Apache Airflow](https://airflow.apache.org/) â€” OrquestraÃ§Ã£o de pipelines
- [MongoDB Atlas](https://www.mongodb.com/atlas/database) â€” Armazenamento de dados brutos
- [PostgreSQL](https://www.postgresql.org/) â€” Armazenamento analÃ­tico (Data Warehouse)
- [Docker & Docker Compose](https://docs.docker.com/) â€” Infraestrutura do projeto
- [Streamlit](https://streamlit.io/) â€” Dashboard para visualizaÃ§Ã£o dos dados

---



## ğŸ“¦ Estrutura do Projeto

```bash
unifor-dataops-pipeline/
â”œâ”€â”€ dags/                   # DAGs do Airflow
â”œâ”€â”€ docker-compose.yml      # OrquestraÃ§Ã£o dos serviÃ§os
â”œâ”€â”€ init/                   # Scripts de inicializaÃ§Ã£o do banco
â”œâ”€â”€ logs/                   # Logs do Airflow
â”œâ”€â”€ plugins/                # Plugins personalizados do Airflow
â”œâ”€â”€ scripts/                # Scripts de ingestÃ£o e transformaÃ§Ã£o de dados
â”œâ”€â”€ streamlit/              # AplicaÃ§Ã£o Streamlit para visualizaÃ§Ã£o dos dados
â””â”€â”€ config/                 # Arquivos de configuraÃ§Ã£o e .env
```

---

## ğŸš€ Como Executar o Projeto

> PrÃ©-requisitos: Docker e Docker Compose instalados

1. Clone o repositÃ³rio:

```bash
git clone https://github.com/felipesoaresdev/unifor-dataops-pipeline.git
cd unifor-dataops-pipeline
```

2. Crie um arquivo `.env` com as variÃ¡veis necessÃ¡rias (exemplo em `config/.env.example`).

3. Suba os containers com Docker Compose:

```bash
docker compose up -d
```

4. Acesse os serviÃ§os:

* Airflow: [http://localhost:8081](http://localhost:8081)
* Streamlit Dashboard: [http://localhost:8501](http://localhost:8501)

---

## ğŸ“Œ Funcionalidades

* IngestÃ£o de dados da API pÃºblica do TabNews via Python
* Armazenamento dos dados brutos no MongoDB
* Processamento e transformaÃ§Ã£o com Apache Spark
* GravaÃ§Ã£o dos dados transformados em modelo estrela no PostgreSQL
* Dashboard interativo com mÃ©tricas e grÃ¡ficos via Streamlit

---

## ğŸ” SeguranÃ§a

> âš ï¸ Este projeto Ã© apenas para fins educacionais e de demonstraÃ§Ã£o. **NÃ£o utilize as credenciais padrÃ£o ou deixe-as no cÃ³digo-fonte em ambientes de produÃ§Ã£o.**

RecomendaÃ§Ãµes:

* Use variÃ¡veis de ambiente para credenciais
* Nunca exponha senhas ou chaves diretamente no cÃ³digo
* Altere o usuÃ¡rio/senha padrÃ£o do Airflow (`admin/admin`) antes de expor publicamente

---

## ğŸ‘¨â€ğŸ’» Autores

Desenvolvido por:

[Felipe Soares](https://github.com/felipesoaresdev) â€” Analista de Sistemas | Engenheiro de Dados.

[Winiston Freitas](https://github.com/winistonvf) â€” Analista de Sistemas | Engenheiro de Dados.

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a [MIT License](LICENSE).

